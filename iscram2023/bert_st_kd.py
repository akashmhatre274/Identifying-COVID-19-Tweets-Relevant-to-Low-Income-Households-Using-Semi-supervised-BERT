# -*- coding: utf-8 -*-
"""BERT_ST_KD.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JxaVOMpS5rsjUq1PC3pqxZI_vYiRhbKu
"""

import os
import pickle
import numpy as np
import pandas as pd



import torch
import torch.autograd as autograd
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence
from torch.utils.data import TensorDataset, DataLoader, Subset
from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence


import matplotlib.pyplot as plt
import gc

# Unique to this file
from transformers import AutoTokenizer, AutoModel
from transformers import BertForSequenceClassification
from transformers import AdamW
from transformers import get_linear_schedule_with_warmup

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import precision_recall_fscore_support
from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score


from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification

from train_test import get_device, compute_accuracy, test_ST


# Depending on your GPU you can either increase or decrease this value
batch_size = 16
total_epoch = 10
learning_rate = 1e-5
iter_num = 1

# Find out how many labels are in the dataset
with open('covid_dataset/5_class_map.pkl','rb') as f:
    labels = pickle.load(f)
labels_in_dst = len(labels)



model_map= {
    #"tinybert": "huawei-noah/TinyBERT_General_4L_312D",
    "covidbert": "digitalepidemiologylab/covid-twitter-bert-v2",
    #"distilbert": "distilbert-base-uncased",
    "bertweet": "vinai/bertweet-base",
    "bertweetcovid": "vinai/bertweet-covid19-base-uncased"
}
# train teacher model for self training
# the train_st.dst is TensorDataset that assign each tweet a weight 1, that's the only difference with train.dst

cwd = os.getcwd()

dst_path = 'preprocessed_data/{}.dst'
dst_path = os.path.join(cwd,'preprocessed_data/{}-{{}}.dst'.format("bertweetcovid"))

train = torch.load(dst_path.format('train_st'))
val = torch.load(dst_path.format('val'))
test = torch.load(dst_path.format('test'))
unlabeled = torch.load(dst_path.format('19k'))

input_ids, masks, _ = zip(*unlabeled)

input_ids = torch.stack(input_ids)
masks = torch.stack(masks)

df_19k = pd.read_csv('covid_dataset/splits/19k_avg_v2.1.csv')

pred_probs = df_19k[['class0', 'class1', 'class2', 'class3', 'class4']].to_numpy()

paper_pred_prob = torch.tensor(pred_probs, dtype=torch.float32)

unlabeled_prob = TensorDataset(input_ids, masks, paper_pred_prob )
print(unlabeled_prob.__len__())

unlabeled_prob

# cross entropy loss for two probability distribution
# https://discuss.pytorch.org/t/how-should-i-implement-cross-entropy-loss-with-continuous-target-outputs/10720/18
def cross_entropy(pred, soft_targets):
    logsoftmax = nn.LogSoftmax(dim=1)
    return torch.mean(torch.sum(- soft_targets * logsoftmax(pred), 1))

#assuming pred and soft_targets are both Variables with shape (batchsize, num_of_classes), 
#each row of pred is predicted logits and each row of soft_targets is a discrete distribution.

# Do KD with unlabeled data on a given model student_path
def student_distill(student_path, train, unlabel, val, test, batch_size, total_epoch, labels_in_dst, learning_rate):
    global model_map

    trainloader = DataLoader(train, shuffle=True, batch_size=batch_size)
    valloader = DataLoader(val, shuffle=False, batch_size=batch_size)
    unlabel_loader = DataLoader(unlabel, shuffle=True, batch_size=batch_size)
    
    device = get_device()


    model = AutoModelForSequenceClassification.from_pretrained(model_map['bertweetcovid'], 
                                                          num_labels=labels_in_dst,
                                                          return_dict=True)
    
    checkpoint = torch.load(student_path)
    model.load_state_dict(checkpoint['model_state_dict'])
    
    save_model_path = "distill_" + student_path
    model = model.to(device)
    gc.collect()

    optimizer = AdamW(model.parameters(), lr=learning_rate)

    sum_loss = []
    sum_val = []
    
    val_f1_average = []

    for epoch in range(0, total_epoch):
        print('Epoch:', epoch)
        train_loss, valid_loss = [], []
        model.train()
        for input_ids, attention_mask, labels in unlabel_loader:
            input_ids = input_ids.to(device)
            attention_mask = attention_mask.to(device)
            labels = labels.to(device) # teacher predicted probabilities

            
            optimizer.zero_grad()
            output1 = model(input_ids, attention_mask=attention_mask)
            
            logits = output1.logits

            loss = cross_entropy(logits, labels)
#             
            
            loss.backward()
            optimizer.step()
            train_loss.append(loss.item())
        sum_loss.append(sum(train_loss)/len(train))  
        print('Loss: {:.4f}'.format(sum_loss[epoch-1]))

#       evaluation part 
        model.eval()
        with torch.no_grad():
            predictions = []
            true_labels = []
            for input_ids, attention_mask, labels in valloader:
                input_ids = input_ids.to(device)
                attention_mask = attention_mask.to(device)
                labels = labels.to(device)
                output = model(input_ids, attention_mask=attention_mask)
                predictions.append(output.logits.clone().detach())
                true_labels.append(labels.clone().detach())
            predictions = torch.cat(predictions)
            true_labels = torch.cat(true_labels)
            predictions = predictions.cpu()
            true_labels = true_labels.cpu()

            # val_f1 is weighted f1 
            acc, precision, recall, f1_macro, val_f1  = compute_accuracy(predictions, true_labels)
            print("validation performance at epoch: ", epoch, acc, precision, recall, f1_macro, val_f1)
            
            
            best_f1 = max(val_f1_average, default=-1)
            best_model_state = ''
            # Save the best model seen so far
            if val_f1 > best_f1:
                best_f1 = val_f1
                torch.save(model.state_dict(), save_model_path)
            
            val_f1_average.append(val_f1)
    
        # test
        model.eval()
        testloader = DataLoader(test, shuffle=False, batch_size=batch_size)

        with torch.no_grad():
            predictions = []
            true_labels = []
            pred_prob = []
            for input_ids, attention_mask, labels in testloader:
                input_ids = input_ids.to(device)
                attention_mask = attention_mask.to(device)
                labels = labels.to(device)

                output = model(input_ids, attention_mask=attention_mask)
                logits = output.logits.clone().detach()

                predictions.append(logits)
                true_labels.append(labels.clone().detach())

                softmax = torch.nn.Softmax(dim=1)
                prob_batch = softmax(logits)
                prob_batch = prob_batch.cpu().numpy()
                pred_prob.append(prob_batch)

            predictions = torch.cat(predictions)
            true_labels = torch.cat(true_labels)
            predictions = predictions.cpu()
            true_labels = true_labels.cpu()

            flat_prob = np.concatenate(pred_prob, axis=0)

            pred_labels = np.argmax(flat_prob, axis=1).flatten()

            acc, precision, recall,f1_macro, f1_score  = compute_accuracy(predictions, true_labels)

            print("test model performance at epoch : ", epoch, acc, precision, recall,f1_macro, f1_score)

def test_ST2(checkpoint_path, test, labels_in_dst, batch_size):
    global model_map
    test_f1_average = []
    test_precision = []
    test_recall = []
    test_acc = []
    test_f1 = []
    
    device = get_device()  
    
    model = AutoModelForSequenceClassification.from_pretrained(model_map['bertweetcovid'], 
                                                          num_labels=labels_in_dst,
                                                          return_dict=True)
    model.load_state_dict(torch.load(checkpoint_path))


    model = model.to(device)
    model.eval()
    flat_prob = []
    pred_labels = []
    
    testloader = DataLoader(test, shuffle=False, batch_size=batch_size)
    
    with torch.no_grad():
            predictions = []
            true_labels = []
            pred_prob = []
            for input_ids, attention_mask, labels in testloader:
                input_ids = input_ids.to(device)
                attention_mask = attention_mask.to(device)
                labels = labels.to(device)
                
                output = model(input_ids, attention_mask=attention_mask)
                logits = output.logits.clone().detach()
                
                predictions.append(logits)
                true_labels.append(labels.clone().detach())
                
                softmax = torch.nn.Softmax(dim=1)
                prob_batch = softmax(logits)
                prob_batch = prob_batch.cpu().numpy()
                pred_prob.append(prob_batch)
                
            predictions = torch.cat(predictions)
            true_labels = torch.cat(true_labels)
            predictions = predictions.cpu()
            true_labels = true_labels.cpu()
            
            flat_prob = np.concatenate(pred_prob, axis=0)
               
            pred_labels = np.argmax(flat_prob, axis=1).flatten()
            
            acc, precision, recall,f1_macro, f1_score  = compute_accuracy(predictions, true_labels)
            test_acc.append(acc)
            test_f1_average.append(f1_macro)
            test_f1.append(f1_score)
            test_precision.append(precision)
            test_recall.append(recall)
            print("test performance: ", acc, precision, recall,f1_macro, f1_score)
            
    return pred_labels, flat_prob

_, _ = test_ST("bertweetcovid_ST_1iter_500eachclass.pth", test, labels_in_dst, batch_size)

batch_size = 16
total_epoch = 10
learning_rate = 1e-5

student_distill("0bertweetcovid_ST_1iter_500each16batch10epochs.pth", train, unlabeled_prob, val, test, batch_size, total_epoch, labels_in_dst, learning_rate)

# run 1: self training only
for i in range(0,5):
    _, _ = test_ST(str(i)+"bertweetcovid_ST_1iter_500each16batch10epochs.pth", test, labels_in_dst, 16)
    batch_size = 16
    total_epoch = 10
    learning_rate = 1e-5
    
    student_distill(str(i)+"bertweetcovid_ST_1iter_500each16batch10epochs.pth", train, unlabeled_prob, val, test, batch_size, total_epoch, labels_in_dst, learning_rate)

    _, _ = test_ST2("distill_"+str(i)+"bertweetcovid_ST_1iter_500each16batch10epochs.pth", test, labels_in_dst, 16)
#'''
